version: '3.8'

services:
  # Ollama is managed by the Electron app directly, not through Docker
  
  neo4j:
    image: neo4j:5.26.0
    container_name: ae-desktop-neo4j
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/password123
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_memory_heap_max__size=512M
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - ae_neo4j_data:/data
      - ae_neo4j_logs:/logs
    networks:
      - ae-desktop-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 30s
      timeout: 10s
      retries: 5

  graphiti-service:
    build:
      context: .
      dockerfile: Dockerfile.graphiti
    container_name: ae-desktop-graphiti
    ports:
      - "8100:8100"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password123
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_LLM_MODEL=${OLLAMA_LLM_MODEL:-gemma3n:e2b}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - GRAPHITI_SERVICE_PORT=8100
    depends_on:
      neo4j:
        condition: service_healthy
    networks:
      - ae-desktop-network
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

networks:
  ae-desktop-network:
    driver: bridge

volumes:
  ae_neo4j_data:
  ae_neo4j_logs: